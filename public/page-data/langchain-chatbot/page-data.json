{"componentChunkName":"component---src-templates-blog-post-js","path":"/langchain-chatbot/","result":{"data":{"wpPost":{"id":"cG9zdDoxNTE5OA==","title":"Langchain Chatbot","excerpt":"","content":"<div class=\"fusion-fullwidth fullwidth-box fusion-builder-row-1 fusion-flex-container has-pattern-background has-mask-background nonhundred-percent-fullwidth non-hundred-percent-height-scrolling\" style=\"--awb-border-radius-top-left:0px;--awb-border-radius-top-right:0px;--awb-border-radius-bottom-right:0px;--awb-border-radius-bottom-left:0px;--awb-flex-wrap:wrap;\" ><div class=\"fusion-builder-row fusion-row fusion-flex-align-items-flex-start fusion-flex-content-wrap\" style=\"max-width:1310.4px;margin-left: calc(-4% / 2 );margin-right: calc(-4% / 2 );\"><div class=\"fusion-layout-column fusion_builder_column fusion-builder-column-0 fusion_builder_column_1_1 1_1 fusion-flex-column\" style=\"--awb-bg-size:cover;--awb-width-large:100%;--awb-margin-top-large:70px;--awb-spacing-right-large:1.92%;--awb-margin-bottom-large:20px;--awb-spacing-left-large:1.92%;--awb-width-medium:100%;--awb-order-medium:0;--awb-spacing-right-medium:1.92%;--awb-spacing-left-medium:1.92%;--awb-width-small:100%;--awb-order-small:0;--awb-spacing-right-small:1.92%;--awb-spacing-left-small:1.92%;\" data-scroll-devices=\"small-visibility,medium-visibility,large-visibility\"><div class=\"fusion-column-wrapper fusion-column-has-shadow fusion-flex-justify-content-flex-start fusion-content-layout-column\"><div class=\"fusion-text fusion-text-1\" style=\"--awb-font-size:38px;\"><h1>How To Build a Custom Chatbot Using LangChain With Examples</h1>\n</div><nav class=\"fusion-breadcrumbs awb-yoast-breadcrumbs fusion-breadcrumbs-1\" style=\"--awb-margin-top:-20px;--awb-font-size:16px;--awb-text-color:#000000;--awb-breadcrumb-sep:&#039;/&#039;;\" aria-label=\"Breadcrumb\"><span><span><a href=\"/\">Home</a></span> » <span><a href=\"/blog/\">Blog</a></span> » <span class=\"breadcrumb_last\" aria-current=\"page\">How To Build a Custom Chatbot Using LangChain With Examples</span></span></nav><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-1 hover-type-none\"><img decoding=\"async\" width=\"1280\" height=\"769\" alt=\"LangChain Chatbot\" title=\"LangChain Chatbot\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/LangChain-Chatbot.webp\" class=\"lazyload img-responsive wp-image-15225\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271280%27%20height%3D%27769%27%20viewBox%3D%270%200%201280%20769%27%3E%3Crect%20width%3D%271280%27%20height%3D%27769%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-200x120.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-300x180.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-400x240.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-600x360.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-768x461.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-800x481.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-1024x615.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot-1200x721.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/LangChain-Chatbot.webp 1280w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1280px\" /></span></div></div></div></div></div><div class=\"fusion-fullwidth fullwidth-box fusion-builder-row-2 fusion-flex-container has-pattern-background has-mask-background nonhundred-percent-fullwidth non-hundred-percent-height-scrolling\" style=\"--awb-border-radius-top-left:0px;--awb-border-radius-top-right:0px;--awb-border-radius-bottom-right:0px;--awb-border-radius-bottom-left:0px;--awb-margin-top-small:120px;--awb-min-height:2000px;--awb-flex-wrap:wrap;\" ><div class=\"fusion-builder-row fusion-row fusion-flex-align-items-flex-start fusion-flex-content-wrap\" style=\"max-width:1310.4px;margin-left: calc(-4% / 2 );margin-right: calc(-4% / 2 );\"><div class=\"fusion-layout-column fusion_builder_column fusion-builder-column-1 fusion_builder_column_3_4 3_4 fusion-flex-column\" style=\"--awb-bg-size:cover;--awb-width-large:75%;--awb-margin-top-large:0px;--awb-spacing-right-large:2.56%;--awb-margin-bottom-large:20px;--awb-spacing-left-large:2.56%;--awb-width-medium:100%;--awb-order-medium:0;--awb-spacing-right-medium:1.92%;--awb-spacing-left-medium:1.92%;--awb-width-small:100%;--awb-order-small:0;--awb-margin-top-small:-150px;--awb-spacing-right-small:1.92%;--awb-spacing-left-small:1.92%;\" id=\"intro\" data-scroll-devices=\"small-visibility,medium-visibility,large-visibility\"><div class=\"fusion-column-wrapper fusion-column-has-shadow fusion-flex-justify-content-flex-start fusion-content-layout-column\"><div class=\"fusion-title title fusion-title-1 fusion-sep-none fusion-title-text fusion-title-size-two\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:35px;\" id=\"introduction\"><h2 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:35;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><h2><span style=\"font-weight: 400;\">1. Introduction</span></h2></a></h2></div><div class=\"fusion-text fusion-text-2\" style=\"--awb-margin-top:-40px;\" id=\"setting\"><p><span style=\"font-weight: 400;\">Imagine a world where technology doesn't just inform you, it engages with you. Where a digital companion walks alongside you, offering insightful advice, answering your questions, and even anticipating your needs. This isn't a scene from a futuristic sci-fi flick; it's the dawn of a new era in artificial intelligence, one where </span><a href=\"http://hrchatbot.deligence.ca/chat\" target=\"_blank\" rel=\"noopener\"><span style=\"font-weight: 400;\"><strong>custom chatbots built with frameworks like LangChain</strong></span></a><span style=\"font-weight: 400;\"> are blurring the lines between machine and meaningful connection. </span></p>\n<p><span style=\"font-weight: 400;\">But what is </span><strong><a href=\"https://www.langchain.com/\" target=\"_blank\" rel=\"noopener\">LangChain</a></strong><span style=\"font-weight: 400;\">, you ask? Think of it as your virtual workshop, a set of tools and building blocks specifically designed for crafting captivating chatbots. Unlike pre-programmed scripts, Langchain empowers you to define the conversation flow, inject human-like nuance into your chatbot's responses, and connect it to the real world through external data and APIs. It's the bridge between your creative vision and the powerful capabilities of Large Language Models (LLMs), allowing you to shape a digital </span><strong><a href=\"https://en.wikipedia.org/wiki/Michelangelo\" target=\"_blank\" rel=\"noopener\">Michelangelo</a></strong><span style=\"font-weight: 400;\"> of conversation.</span></p>\n<p><span style=\"font-weight: 400;\">Gone are the days of robotic, pre-programmed dialogs. With LangChain, you can create multi-step interactions, integrate external knowledge sources, and even imbue your chatbot with memory, fostering a sense of familiarity and genuine connection with your users. Whether you're a seasoned developer or a curious entrepreneur, this blog will be your guide, unveiling the secrets of LangChain and empowering you to build your very own AI-powered conversational companion.</span></p>\n<p><span style=\"font-weight: 400;\">We have written an in-depth blog on LangChain that you can read here: </span><strong><a href=\"https://www.deligence.com/what_is_langchain_ai_app_development_framework_explained/\" target=\"_blank\" rel=\"noopener\">What is LangChain?</a></strong></p>\n<p><span style=\"font-weight: 400;\">In the upcoming sections, we'll delve deep into the practicalities of building your LangChain chatbot, equipping you with the knowledge and tools to bring your vision to life. We have also created our chatbot using LangChain, which you can view and test from </span><i><span style=\"font-weight: 400;\">here</span></i><span style=\"font-weight: 400;\">. Let's begin building!</span></p>\n<p><i><span style=\"font-weight: 400;\">Note: All the examples in this blog are using </span></i><strong><a href=\"https://github.com/langchain-ai/langchainjs\" target=\"_blank\" rel=\"noopener\"><i>LangChainJS</i></a></strong><i><span style=\"font-weight: 400;\">, connected with </span></i><strong><a href=\"https://openai.com/blog/openai-api\" target=\"_blank\" rel=\"noopener\"><i>OpenAI API</i></a></strong><i><span style=\"font-weight: 400;\">, and </span></i><strong><a href=\"https://www.pinecone.io/\" target=\"_blank\" rel=\"noopener\"><i>Pinecone</i></a></strong><i><span style=\"font-weight: 400;\">. </span></i></p>\n</div><div class=\"fusion-title title fusion-title-2 fusion-sep-none fusion-title-text fusion-title-size-two\" style=\"--awb-text-color:#202020;--awb-font-size:35px;\" id=\"nextjs\"><h2 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:35;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><h2><span style=\"font-weight: 400;\">2. Setting Up the Development Environment</span></h2></a></h2></div><div class=\"fusion-title title fusion-title-3 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-font-size:28px;\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">2.1 Next.js</span></a></h3></div><div class=\"fusion-text fusion-text-3\" id=\"nextjs\"><p><span style=\"font-weight: 400;\">To install next.js, you would have to do the following: </span></p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-1 > .CodeMirror, .fusion-syntax-highlighter-1 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-1 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-1 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-1 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_1\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_1\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_1\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">npx create-next-app@latest\n  \nWhile installing, you will see the following prompts:\n\nWhat is your project named? my-app\n\nWould you like to use TypeScript? No / Yes\n\nWould you like to use ESLint? No / Yes\n\nWould you like to use Tailwind CSS? No / Yes\n\nWould you like to use `src/` directory? No / Yes\n\nWould you like to use App Router? (recommended) No / Yes\n\nWould you like to customize the default import alias (@/*)? No / Yes\n\nWhat import alias would you like configured? @/*\n\nAfter the prompts, create-next-app will create a folder with your project name and install the required dependencies.</textarea></div><div class=\"fusion-title title fusion-title-4 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"pinecone\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">2.2 Pinecone</span></a></h3></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-2 hover-type-none\"><img decoding=\"async\" width=\"2560\" height=\"1446\" alt=\"Pinecone API Key\" title=\"Pinecone API Key\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-scaled.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Pinecone-API-Key-scaled.webp\" class=\"lazyload img-responsive wp-image-15221\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%272560%27%20height%3D%271446%27%20viewBox%3D%270%200%202560%201446%27%3E%3Crect%20width%3D%272560%27%20height%3D%271446%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-200x113.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-300x169.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-400x226.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-600x339.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-768x434.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-800x452.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-1024x579.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-1200x678.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-1536x868.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Pinecone-API-Key-scaled.webp 2560w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-text fusion-text-4\"><p><span style=\"font-weight: 400;\">To setup Pinecone Index sign in with your details to login at </span><a href=\"https://www.pinecone.io\" target=\"_blank\" rel=\"noopener\"><span style=\"font-weight: 400;\">https://www.pinecone.io</span></a></p>\n<p><span style=\"font-weight: 400;\">Click on \"Get Started\". </span></p>\n<p><span style=\"font-weight: 400;\">Fill in your Name, Goal, Purpose of index, and preferred coding language.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Now Create an index with an </span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Configure your index with dimensions 1536 as specified for a vector database.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Select your storage type or Pod type , default being starter.</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Now create an API key for the pinecone Index by entering the API key name. Once the API key has been created it will be shown as your project application API key.</span></p>\n<p><span style=\"font-weight: 400;\">Connect the index to your application using the code generated by the pinecone app according to your specifications.</span></p>\n</div><div class=\"fusion-title title fusion-title-5 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"openAI\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">2.3 LangChain and OpenAI API Key</span></a></h3></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-3 hover-type-none\"><img decoding=\"async\" width=\"2560\" height=\"1524\" alt=\"Open AI API Key\" title=\"Open AI API Key\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-scaled.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Open-AI-API-Key-scaled.webp\" class=\"lazyload img-responsive wp-image-15223\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%272560%27%20height%3D%271524%27%20viewBox%3D%270%200%202560%201524%27%3E%3Crect%20width%3D%272560%27%20height%3D%271524%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-200x119.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-300x179.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-400x238.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-600x357.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-768x457.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-800x476.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-1024x610.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-1200x714.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-1536x914.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Open-AI-API-Key-scaled.webp 2560w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-text fusion-text-5\"><p><span style=\"font-weight: 400;\">To get started, install LangChain with the following command:</span></p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-2 > .CodeMirror, .fusion-syntax-highlighter-2 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-2 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-2 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-2 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_2\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_2\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_2\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">npm install -S langchain</textarea></div><div class=\"fusion-text fusion-text-6\"><p><span style=\"font-weight: 400;\">LangChain can be used in Vercel/Next.js. Next.js supports using LangChain in frontend components, Serverless functions and Edge functions. It can be imported using the following syntax:</span></p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-3 > .CodeMirror, .fusion-syntax-highlighter-3 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-3 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-3 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-3 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_3\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_3\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_3\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">import { OpenAI } from \"langchain/llms/openai\";</textarea></div><div class=\"fusion-text fusion-text-7\"><ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">The OpenAI API uses API keys for authentication. To access the OpenAI key, make an account on the OpenAI platform. Go to API keys and Generate API key with the option :</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Create new secret key</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Setup the  OpenAI API key in .env file(environment file) in next.js as:</span></li>\n</ul>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-4 > .CodeMirror, .fusion-syntax-highlighter-4 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-4 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-4 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-4 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_4\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_4\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_4\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">OPENAI_API_KEY=<api key></textarea></div><div class=\"fusion-text fusion-text-8\"><p><span style=\"font-weight: 400;\">Make the changes in next.config.js by inserting this line of code as an object</span></p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-5 > .CodeMirror, .fusion-syntax-highlighter-5 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-5 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-5 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-5 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_5\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_5\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_5\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">env:{\n     OPENAI_API_KEY: process.env.OPENAI_API_KEY,\n      }</textarea></div><div class=\"fusion-text fusion-text-9\"><p><span style=\"font-weight: 400;\">Wherever this api key is to be used , use it as process.env.OPENAI_API_KEY</span></p>\n</div><div class=\"fusion-title title fusion-title-6 fusion-sep-none fusion-title-text fusion-title-size-two\" style=\"--awb-text-color:#202020;--awb-font-size:35px;\" id=\"building_blocks\"><h2 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:35;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><h2><span style=\"font-weight: 400;\">3. Understanding the Building Blocks</span></h2></a></h2></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-4 hover-type-none\"><img decoding=\"async\" width=\"1920\" height=\"1080\" alt=\"Building Blocks Of LangChain\" title=\"Building Blocks Of LangChain\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain.webp\" class=\"lazyload img-responsive wp-image-15229\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271920%27%20height%3D%271080%27%20viewBox%3D%270%200%201920%201080%27%3E%3Crect%20width%3D%271920%27%20height%3D%271080%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-200x113.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-300x169.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-400x225.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-600x338.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-768x432.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-800x450.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-1024x576.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-1200x675.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain-1536x864.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Building-Blocks-Of-LangChain.webp 1920w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-title title fusion-title-7 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"prompt_templates\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">3.1 Prompt Templates</span></a></h3></div><div class=\"fusion-text fusion-text-10\"><p><span style=\"font-weight: 400;\">Prompt Templates in LangChain are powerful tools that help you build customized prompts for your large language models (LLMs) with ease and flexibility. Instead of crafting individual prompts for every specific case, you define a template once with placeholders. Then, you simply \"fill in the blanks\" with different values to create unique prompts on the fly. Placeholders can be any kind of data, like strings, numbers, dictionaries, or even data classes. This lets you personalize prompts based on user queries, context, or other information. Think of Prompt Templates in LangChain as Lego blocks for building instructions for your language model. You create reusable templates with empty slots, then plug in different words, sentences, or even whole blocks of data to fit the task at hand.</span></p>\n</div><div class=\"fusion-title title fusion-title-8 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">3.1.1 Example of Prompt Template in LangChain</span></a></h4></div><div class=\"fusion-text fusion-text-11\" id=\"Example_of_Prompt_Template\"><p>Imagine you're writing a story but want your model to fill in missing details. Here's an example Prompt Template:</p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-6 > .CodeMirror, .fusion-syntax-highlighter-6 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-6 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-6 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-6 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_6\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_6\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_6\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">const storyTemplate = `Once upon a time, in a {kingdomType} called {kingdomName}, lived a brave {characterType} named {characterName}. One day, {triggerEvent}...\n\nWrite the rest of the story, keeping {kingdomType}, {kingdomName}, {characterType}, and {characterName} consistent throughout. Be creative and exciting!`;\n</textarea></div><div class=\"fusion-text fusion-text-12\"><p>Then, when you need a new story, you just fill in the blanks:</p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-7 > .CodeMirror, .fusion-syntax-highlighter-7 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-7 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-7 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-7 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_7\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_7\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_7\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">const fairyTalePrompt = storyTemplate.format({\n  kingdomType: \"enchanted forest\",\n  kingdomName: \"Moonwood\",\n  characterType: \"talking mouse\",\n  characterName: \"Pip\",\n  triggerEvent: \"a lost princess stumbled upon his mushroom house\",\n});\n</textarea></div><div class=\"fusion-text fusion-text-13\"><p>Now, your model has all the base information to write a unique fairy tale about Pip the talking mouse and the lost princess!</p>\n<p>In a LangChain chatbot, Prompt Templates are your secret weapon for crafting dynamic and engaging responses.</p>\n<p>Imagine a simple FAQ chatbot. Here's a template to handle user questions:</p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-8 > .CodeMirror, .fusion-syntax-highlighter-8 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-8 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-8 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-8 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_8\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_8\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_8\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">const answerTemplate = `Hi {user_name}, thanks for your question!\n\nI understand you're asking about {question_topic}. Let me see if I can help...\n\n{answer_details}\n\nIs there anything else you'd like to know? `\n\nPlaceholders:\n\n{user_name}: Automatically inserts the user's name for personalization.\n\n{question_topic}: Extracts the main topic of the user's question.\n\n{answer_details}: This is where you'd plug in the actual answer content, retrieved from your knowledge base or AI model.\n</textarea></div><div class=\"fusion-text fusion-text-14\"><p><strong>Usage:</strong></p>\n<p>When a user asks a question, you analyze it to extract the topic (question_topic). Then, you populate the template with the extracted topic and the corresponding answer details retrieved based on that topic. This generates a personalized and informative response for the user.</p>\n</div><div class=\"fusion-title title fusion-title-9 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">3.2 Output Parser</span></a></h3></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-5 hover-type-none\" id=\"prompt_templates\"><img decoding=\"async\" width=\"1920\" height=\"1080\" alt=\"Output Parser\" title=\"Output Parser\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Output-Parser.webp\" class=\"lazyload img-responsive wp-image-15222\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271920%27%20height%3D%271080%27%20viewBox%3D%270%200%201920%201080%27%3E%3Crect%20width%3D%271920%27%20height%3D%271080%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-200x113.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-300x169.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-400x225.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-600x338.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-768x432.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-800x450.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-1024x576.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-1200x675.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser-1536x864.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Output-Parser.webp 1920w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-text fusion-text-15\" id=\"types_of_Output_Parsers\"><p><span style=\"font-weight: 400;\">Output parsers are your trusty companions for taming the raw text generated by large language models (LLMs). Imagine you ask your LLM to write a poem, but instead of a beautiful verse, you get a jumbled mess of words. That's where output parsers come in. They take the LLM's output and transform it into a more structured and useful format. This could be JSON data, Python data classes, Database rows or Custom formats.</span></p>\n</div><div class=\"fusion-title title fusion-title-10 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">3.2.1 Different types of Output Parsers in LangChain</span></a></h4></div><div class=\"fusion-text fusion-text-16\"><p><span style=\"font-weight: 400;\">StringOutputParser: Converts raw text from LLM to text.</span></p>\n<p><span style=\"font-weight: 400;\">StructuredOutputParser: Converts text into JSON objects based on predefined schemas.</span></p>\n<p><span style=\"font-weight: 400;\">PydanticOutputParser: Generates Python data classes from the LLM's output.</span></p>\n<p><span style=\"font-weight: 400;\">EnumOutputParser: Parses text into predefined categories or values.</span></p>\n<p><span style=\"font-weight: 400;\">DateTimeOutputParser: Extracts date and time information from the generated text.</span></p>\n<p><span style=\"font-weight: 400;\">Basically, the Prompt template sets the course for the LLM's journey, while the output parser refines the destination and makes it readily available for your use.</span></p>\n</div><div class=\"fusion-text fusion-text-17\"><p>Here is an example of StringOutputParser transforming the raw LLM/ChatModel output into a consistent string format:</p>\n</div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-9 > .CodeMirror, .fusion-syntax-highlighter-9 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-9 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-9 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-9 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_9\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_9\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_9\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">import { PromptTemplate } from \"langchain/prompts\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { RunnableSequence } from \"langchain/schema/runnable\";\nimport { StringOutputParser } from \"langchain/schema/output_parser\";\n\nconst model = new ChatOpenAI({\nopenAIApiKey : “Your Key Here”,\ntemperature : 0.7,\n});\nconst promptTemplate = PromptTemplate.fromTemplate(\n  \"Tell me a {adjective} quote about {topic}\"\n);\nconst outputParser = new StringOutputParser();\n\nconst chain = RunnableSequence.from([promptTemplate, model, outputParser]);\n\nconst result = await chain.invoke({ \nadjective : “beautiful”,\ntopic: “sunrise”,\n});\n\nconsole.log(result);\n</textarea></div><div class=\"fusion-title title fusion-title-11 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"Stop_Sequence\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">3.3 Stop Sequence</span></a></h3></div><div class=\"fusion-text fusion-text-18\"><p><span style=\"font-weight: 400;\">In LangChain, a stop sequence is a specific string or pattern that, when encountered in the model's generated text, signals the model to stop generating further output. It serves as a control mechanism to prevent unnecessary text generation, manage model responses, and ensure efficient use of resources. Stop sequences can be pre-programmed into prompts or inserted by the LLM to trigger parsing at specific points, ensuring relevant data extraction. By effectively utilizing stop sequences, you can gain more control over the model's text generation process, ensuring concise, relevant, and efficient responses in your LangChain applications.</span></p>\n</div><div class=\"fusion-title title fusion-title-12 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">3.3.1 Example of Stop Sequence</span></a></h4></div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-10 > .CodeMirror, .fusion-syntax-highlighter-10 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-10 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-10 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-10 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\" id=\"Example_of_Stop_Sequence\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_10\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_10\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_10\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">const model = new ChatOpenAI({\n    stopSequence: \"<|endoftext|>\" // Common stop sequence for OpenAI models\n});\n\nconst prompt = \"Write a poem about love, but stop when you reach the end of the first stanza.\";\nconst poem = await model.generateText(prompt);\n\nconsole.log(poem); // Output will end as soon as the model generates \"<|endoftext|>\"\n</textarea></div><div class=\"fusion-text fusion-text-19\" id=\"Chatbot_Interactions\"><p>By strategically incorporating stop sequences, you can refine your chatbot's interactions, ensure concise and relevant responses, manage task completion, prevent unwanted content, and enhance its overall effectiveness in LangChain applications.</p>\n</div><div class=\"fusion-title title fusion-title-13 fusion-sep-none fusion-title-text fusion-title-size-two\" style=\"--awb-text-color:#202020;--awb-font-size:35px;\"><h2 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:35;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><h2 class=\"fusion-responsive-typography-calculated\" style=\"--fontsize: 35; line-height: 1.4;\" data-fontsize=\"35\" data-lineheight=\"49px\"><span style=\"font-weight: 400;\">4. How To Enhance Your Chatbot's Interactions</span></h2></a></h2></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-6 hover-type-none\"><img decoding=\"async\" width=\"1920\" height=\"1080\" alt=\"Chatbot Interactions\" title=\"Chatbot Interactions\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Chatbot-Interactions.webp\" class=\"lazyload img-responsive wp-image-15228\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271920%27%20height%3D%271080%27%20viewBox%3D%270%200%201920%201080%27%3E%3Crect%20width%3D%271920%27%20height%3D%271080%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-200x113.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-300x169.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-400x225.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-600x338.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-768x432.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-800x450.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-1024x576.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-1200x675.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions-1536x864.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Chatbot-Interactions.webp 1920w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-title title fusion-title-14 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"Function_Schema\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.1 Use Function Schema</span></a></h3></div><div class=\"fusion-text fusion-text-20\"><p><span style=\"font-weight: 400;\">Function Schema in LangChain defines the structure and expected input/output format of functions handled by your large language model (LLM). It acts as a roadmap for developers interacting with the LLM, specifying what it can do and how to utilize its capabilities effectively.</span></p>\n</div><div class=\"fusion-title title fusion-title-15 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.1.1 Key Components of Function Schema</span></a></h4></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-7 hover-type-none\" id=\"Key_Components\"><img decoding=\"async\" width=\"1755\" height=\"1129\" alt=\"Function Schema\" title=\"Function Schema\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Function-Schema.webp\" class=\"lazyload img-responsive wp-image-15226\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271755%27%20height%3D%271129%27%20viewBox%3D%270%200%201755%201129%27%3E%3Crect%20width%3D%271755%27%20height%3D%271129%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-200x129.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-300x193.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-400x257.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-460x295.webp 460w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-600x386.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-768x494.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-800x515.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-1024x659.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-1200x772.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema-1536x988.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Function-Schema.webp 1755w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-text fusion-text-21\"><p><b>Function names and descriptions<br />\n</b><span style=\"font-weight: 400;\">Clearly identify the functionality each function offers and its intended purpose.</span></p>\n<p><b>Input parameters<br />\n</b><span style=\"font-weight: 400;\">Define the expected data types and required/optional parameters for feeding information to the model. This could include text prompts, dialogue history, or specific data structures.</span></p>\n<p><b>Output format<br />\n</b><span style=\"font-weight: 400;\">Specify the format of the LLM's response, whether it's text generation, structured data, or something else. Data types like JSON or custom formats can be defined here.</span></p>\n<p><b>Additional details<br />\n</b><span style=\"font-weight: 400;\">Depending on the model and language used, further information can be included like:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Error codes and handling mechanisms.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Authentication requirements for accessing specific functions.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Versioning information for different model variants.</span></li>\n</ul>\n</div><div class=\"fusion-title title fusion-title-16 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.1.2 Benefits of using Function Schema</span></a></h4></div><div class=\"fusion-text fusion-text-22\" id=\"Benefits_of_Function_Schema\"><p><b>Clarity and understanding<br />\n</b><span style=\"font-weight: 400;\">Developers have a clear understanding of the LLM's capabilities and how to interact with it effectively.</span></p>\n<p><b>Reduced errors<br />\n</b><span style=\"font-weight: 400;\">Specifying input/output formats minimizes confusion and prevents invalid requests or unexpected responses.</span></p>\n<p><b>Improved documentation<br />\n</b><span style=\"font-weight: 400;\">Schema documentation serves as a valuable reference for developers and users unfamiliar with the LLM's functionality.</span></p>\n<p><b>Standardized integration<br />\n</b><span style=\"font-weight: 400;\">Enables easier integration of the LLM with external systems and applications through consistent data formats.</span></p>\n</div><div class=\"fusion-text fusion-text-23\"><h6><i><span style=\"font-weight: 400;\">Side Note:</span></i></h6>\n<h6><i><span style=\"font-weight: 400;\">Visit the OpenAI API documentation (https://beta.openai.com/docs/api-reference) to explore the available functions and their schemas.</span></i></h6>\n</div><div class=\"fusion-title title fusion-title-17 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.1.3 Example of using Function Schemas for specific tasks in a chatbot</span></a></h4></div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-11 > .CodeMirror, .fusion-syntax-highlighter-11 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-11 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-11 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-11 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\" id=\"Function_Schema_for_chatbot\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_11\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_11\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_11\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">import {PromptTemplate} from ‘langchain/prompts’;\nimport {ChatOpenAI} from ‘langchain/chat_models/openai’;\nimport  {JsonOutputFunctionsParser} from ‘langchain/output_parsers’;\nconst prompt = PromptTemplate.fromTemplate(‘Tell me an anecdote about {subject}’);\nconst model = new ChatOpenAi({}); \nconst parser = new JsonOutputFunctionsParser();\nconst functionSchema = [\n{\nname: “joke”,\ndescription: “A joke”,\nparameters: {\n   setup: {\n          type: “string”,\n           description: “The setup for the joke”,\n           },\n    punchline: {\n             type: “string”,\n              description: “The punchline for the joke”,\n              },\n        },\n       required: [“setup”,”punchline”],\n       },\n    },\n{\nname: “anecdote”,\ndescription: “An anecdote”,\nparameters: {\n         type: “object”,\n         properties: {\n              question: {\n                    type: “string”,\n                    description: “A question setting up the anecdote,    \n                     starting with words ‘Did you know that’ ”,\n            },\n             answer: {\n                   type: “string”,\n                   description: “A follow-up to the question, \n                   elaborating the anecdote, starting with the words, \n                    ‘ It’s is very true’ “,\n                      },\n                 },\n              required: [ “question”, “answer” ],\n          },\n    },\n];\nconst chain = prompt.pipe( model.bind({\n     functions: functionSchema,\n     function_call : { name: “joke”, name: “anecdote” },\n})\n).pipe(parser);\nconst result = await chain.invoke({subject: ‘monkey’});\nconsole.log(result);\nOutput:\n\n {\n  question: 'Did you know that monkeys can recognize themselves in a mirror?',\n  answer: \"It's is very true! In a famous experiment, researchers placed a mirror in front of various animals to see if they could recognize themselves. Monkeys were one of the few species that passed the test. They would look at themselves in the mirror and even use it to inspect parts of their bodies that they couldn't normally see. This ability to recognize oneself is a sign of self-awareness, which is quite remarkable for our primate friends!\"\n}\n</textarea></div><div class=\"fusion-title title fusion-title-18 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"Runnable_Sequence\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.2 Use Runnable Sequence</span></a></h3></div><div class=\"fusion-text fusion-text-24\"><p><span style=\"font-weight: 400;\">In LangChain, a runnable sequence refers to a specific type of component used to orchestrate your conversational AI flow. It essentially tells LangChain \"what to do next\" during a user interaction. Runnable sequence can also be defined as a series of components chained together to perform a specific task or process. These components can be:</span></p>\n<p><b>LLMs (Large Language Models)<br />\n</b><span style=\"font-weight: 400;\">Generating text, translating languages, writing different kinds of creative content.</span></p>\n<p><b>Vector stores<br />\n</b><span style=\"font-weight: 400;\">Storing and retrieving text or code embeddings for efficient comparison and retrieval.</span></p>\n<p><b>Output parsers<br />\n</b><span style=\"font-weight: 400;\">Extracting structured data from LLM outputs like facts, emotions, or specific details based on defined schema.</span></p>\n<p><b>Components<br />\n</b><span style=\"font-weight: 400;\">Custom functions or pre-built components specific to your needs.</span></p>\n<p><span style=\"font-weight: 400;\">Each component in the sequence takes the output of the previous one as its input, forming a chain of operations. This allows you to orchestrate complex workflows involving multiple LLM calls, data processing, and custom logic.</span></p>\n</div><div class=\"fusion-title title fusion-title-19 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.2.1 Here's an example of Runnable Sequence in LangChain</span></a></h4></div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-12 > .CodeMirror, .fusion-syntax-highlighter-12 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-12 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-12 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-12 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\" id=\"example_of_Runnable_Sequence\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_12\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_12\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_12\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">const retrievalChain = RunnableSequence.from([\n  { \ncontext: retriever.pipe(formatDocs), \nquestion: new RunnablePassthrough() \n},\n  prompt,\n  model,\n  new StringOutputParser(),\n]);\n</textarea></div><div class=\"fusion-text fusion-text-25\"><p>In this sequence, the first Runnable is an object with two properties: 'context' and 'question'. The 'context' property is a function that retrieves and formats documents and the 'question' property is a new instance of RunnablePassthrough, which simply passes its input to the next Runnable.</p>\n<p>The output of each Runnable is merged with the inputs and passed to the next Runnable in the sequence. This allows each Runnable to use only the inputs it needs and pass all inputs to the next Runnable. This design pattern helps to avoid code duplication and makes the code more modular and easier to maintain.</p>\n</div><div class=\"fusion-title title fusion-title-20 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"Runnable_Map\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.3 Use Runnable Map</span></a></h3></div><div class=\"fusion-text fusion-text-26\"><p><span style=\"font-weight: 400;\">RunnableMap refers to a powerful tool for executing multiple components in parallel and collecting their outputs as a single map. Imagine you have a team of assistants, each specializing in different tasks. RunnableMap empowers you to send them instructions simultaneously and gather their completed work in a neat, organized manner.</span></p>\n<p><span style=\"font-weight: 400;\">Runnable Map basically allows you to execute multiple Runnables in parallel, and to return the output of these Runnables as a map.</span></p>\n</div><div class=\"fusion-title title fusion-title-21 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Runnable_Map_Work\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.3.1 How does Runnable Map Work</span></a></h4></div><div class=\"fusion-text fusion-text-27\"><p><b>Function<br />\n</b><span style=\"font-weight: 400;\">RunnableMap is a built-in component within LangChain.</span></p>\n<p><b>Behavior<br />\n</b><span style=\"font-weight: 400;\">It takes an object as input, where each key points to a separate runnable component or function. RunnableMap then runs all these components concurrently and assembles their outputs into a single map, with each key-value pair corresponding to the original key and the executed component's output.</span></p>\n</div><div class=\"fusion-title title fusion-title-22 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Benefits_of_Runnable_Map\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.3.2 Benefits of Runnable Map</span></a></h4></div><div class=\"fusion-text fusion-text-28\"><p><b>Parallel execution<br />\n</b><span style=\"font-weight: 400;\">You can significantly speed up your workflows by running multiple tasks simultaneously instead of sequentially.</span></p>\n<p><b>Independent processing<br />\n</b><span style=\"font-weight: 400;\">Each component operates independently, allowing for efficient handling of diverse tasks.</span></p>\n<p><b>Organized results<br />\n</b><span style=\"font-weight: 400;\">The output map neatly structures the results, making it easy to access and utilize the generated data.</span></p>\n</div><div class=\"fusion-title title fusion-title-23 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Example_of_Runnable_Map\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.3.3 Example of Runnable Map</span></a></h4></div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-13 > .CodeMirror, .fusion-syntax-highlighter-13 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-13 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-13 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-13 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_13\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_13\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_13\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">import { PromptTemplate } from ‘langchain/prompts’;\nimport { RunnableMap } from ‘langchain/schema/runnable’;\nimport { ChatOpenAI } from ‘langchain/chat_models/openai’;\nimport { StringOutputParser } from ‘langchain/schema/output_parser’;\nconst model = new ChatOpenAI({});\nconst parser = new StringOutputParser();\nconst jokeChain = PromptTemplate.fromTemplate(\n  \"Tell me a joke about {topic}\"\n).pipe(model).pipe(parser);\nconst poemChain = PromptTemplate.fromTemplate(\n  \"write a 4-line poem about {topic}\"\n).pipe(model).pipe(parser);\n\nconst mapChain = RunnableMap.from({\n  joke: jokeChain,\n  poem: poemChain,\n});\n\nconst result = await mapChain.invoke({ topic: \"bear\" });\nconsole.log(result);\n\nOutput:\n\n{\n  joke: \"Why don't bears wear socks? \\n\\nBecause they have bear feet!\",\n  poem: 'In the wild, a bear roams free,\\n' +\n    'A majestic creature, fierce yet serene.\\n' +\n    'With strength unmatched, it commands respect,\\n' +\n    \"Nature's guardian, a symbol of protect.\"\n}\n</textarea></div><div class=\"fusion-title title fusion-title-24 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"Augmented_Generation\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.4 Use Retrieval Augmented Generation (RAG)</span></a></h3></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-8 hover-type-none\"><img decoding=\"async\" width=\"1920\" height=\"1080\" alt=\"RAG\" title=\"RAG\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/RAG.webp\" class=\"lazyload img-responsive wp-image-15230\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271920%27%20height%3D%271080%27%20viewBox%3D%270%200%201920%201080%27%3E%3Crect%20width%3D%271920%27%20height%3D%271080%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-200x113.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-300x169.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-400x225.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-600x338.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-768x432.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-800x450.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-1024x576.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-1200x675.webp 1200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG-1536x864.webp 1536w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/RAG.webp 1920w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1200px\" /></span></div><div class=\"fusion-text fusion-text-29\"><p><span style=\"font-weight: 400;\">In LangChain, RAG stands for Retrieval Augmented Generation. It's a technique that combines generative models, like large language models (LLMs), with retrieval mechanisms to enhance the accuracy and relevance of the generated information.</span></p>\n</div><div class=\"fusion-title title fusion-title-25 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"RAG_work\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.4.1 How does RAG work</span></a></h4></div><div class=\"fusion-text fusion-text-30\"><p><b>Retrieval<br />\n</b><span style=\"font-weight: 400;\">When you provide a prompt or context, the retrieval component searches for relevant documents or data points from external sources like databases, knowledge graphs, or previously processed information.</span></p>\n<p><b>Embedding<br />\n</b><span style=\"font-weight: 400;\">The retrieved documents and your original prompt are converted into numerical representations called embeddings.</span></p>\n<p><b>Guidance<br />\n</b><span style=\"font-weight: 400;\">The LLM uses the retrieved embeddings along with your prompt to inform its text generation process. This ensures the generated output is consistent with the retrieved information and relevant to the provided context.</span></p>\n</div><div class=\"fusion-title title fusion-title-26 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Benefits_of_using_RAG\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.4.2 Benefits of using RAG in LangChain</span></a></h4></div><div class=\"fusion-text fusion-text-31\"><p><b>Improved accuracy and relevance<br />\n</b><span style=\"font-weight: 400;\">The retrieved information acts as a factual backbone for the LLM, reducing the risk of generating inaccurate or irrelevant content.</span></p>\n<p><b>Knowledge integration<br />\n</b><span style=\"font-weight: 400;\">Allows you to easily incorporate external knowledge sources into your LLM's workflow, expanding its reach and capabilities.</span></p>\n<p><b>Contextual awareness<br />\n</b><span style=\"font-weight: 400;\">The LLM is better able to understand the specific context of your request and generate responses that are more tailored and meaningful.</span></p>\n</div><div class=\"fusion-title title fusion-title-27 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"RAG_in_Chatbot\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.4.3 How can RAG be used in a Chatbot</span></a></h4></div><div class=\"fusion-text fusion-text-32\"><p><span style=\"font-weight: 400;\">RAG can significantly enhance your chatbot's capabilities by adding context awareness, improved accuracy, and deeper integration with external knowledge sources. When a user asks a question, RAG retrieves relevant documents like factsheets or official reports, allowing the chatbot to provide factually accurate answers with evidence-based citations. RAG can analyze past conversations and user profiles to personalize responses, tailoring future interactions to the user's specific needs and interests. </span></p>\n</div><div class=\"fusion-title title fusion-title-28 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Cases_of_RAG\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.4.4 Use Cases of RAG in Chatbots</span></a></h4></div><div class=\"fusion-text fusion-text-33\"><p><b>Answering complex questions<br />\n</b><span style=\"font-weight: 400;\">By leveraging retrieved research papers, historical records, or technical manuals, the chatbot can tackle complex inquiries efficiently and accurately, even if they go beyond its basic knowledge base.</span></p>\n<p><b>Guiding user exploration<br />\n</b><span style=\"font-weight: 400;\">When a user expresses interest in a specific topic, RAG can use retrieved resources to suggest relevant articles, videos, or additional information sources, enhancing user engagement and learning.</span></p>\n<p><b>Multilingual communication<br />\n</b><span style=\"font-weight: 400;\">If your chatbot operates in multiple languages, RAG can assist with finding and translating relevant documents, enabling cross-lingual communication and knowledge sharing.</span></p>\n</div><div class=\"fusion-title title fusion-title-29 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Example_of_RAG\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">4.4.5 Example of RAG</span></a></h4></div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-14 > .CodeMirror, .fusion-syntax-highlighter-14 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-14 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-14 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-14 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_14\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_14\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_14\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">import { ChatOpenAI } from \"langchain/chat_models/openai\";\n                    \timport { PromptTemplate } from \"langchain/prompts\";\n                    \timport {\n                    \t  RunnableSequence,\n                    \t  RunnablePassthrough,\n                    \t} from \"langchain/schema/runnable\";\n                    \timport {PDFLoader} from 'langchain/document_loaders/fs/pdf';\n                    \timport { CharacterTextSplitter } from 'langchain/text_splitter';\n                    \timport { StringOutputParser } from \"langchain/schema/output_parser\";\n                    \timport { Pinecone} from '@pinecone-database/pinecone';\n                    \timport {Document}  from 'langchain/document';\n                    \timport {OpenAIEmbeddings} from 'langchain/embeddings/openai';\n                    \timport {PineconeStore} from 'langchain/vectorstores/pinecone';\n                    \t\n                    \tconst model = new ChatOpenAI({\n                    \t\ttemperature: 0.7,\n                    \t\topenAIApiKey:Your openAI API key,\n                    \t});\n                    \tconst bookPath=\"childdevelop.pdf\";\n                    \tconst loader= new PDFLoader(bookPath);\n                    \t    \tconst docs= await loader.load();\n                    \t    \tconsole.log(docs);\n                    \t    \tif(docs.length === 0)\n                    \t    \t{\n                    \t        \tconsole.docs(\"No Docs Found\");\n                    \t    \t}\n                    \t    \tconst splitter= new CharacterTextSplitter({\n                    \t        \tseparator: \"\\n\\n\",\n                    \t       \tchunkSize: 1000,\n                    \t        \tchunkOverlap: 10,\n                    \t    \t});\n                    \t    \tconst splitDocs= await splitter.splitDocuments(docs);\n                    \t    \tconst reduceDocs = splitDocs.map((doc)=>{\n                    \t        \tconst reduceMetadata = {...doc.metadata};\n                    \t            delete reduceMetadata.pdf;\n                    \t        \treturn new Document({\n                    \t            \tpageContent: doc.pageContent,\n                    \t            \tmetadata: reduceMetadata,\n                    \t        \t});\n                    \t    \t});\n                    \t    \tconsole.log(reduceDocs[0]);\n                    \t    \tconsole.log(splitDocs.length);\n                    \t    \tconst client = new Pinecone(\n                    \t    \t{\n                    \t        \tapiKey: Your Pinecone API Key,\n                    \t        \tenvironment:Your Pinecone Environment name ,\n                    \t    \t});\n                    \t    \tconst pineconeIndex = client.Index(Your Pinecone index name);\n                    \t    \tconst vectorStore=await PineconeStore.fromDocuments(reduceDocs,new OpenAIEmbeddings({\n                    \t        \topenAIApiKey:Your openAI API Key,\n                    \t      \t}),{\n                    \t        \tpineconeIndex,\n                    \t    \t});\n                    \tconst retriever = vectorStore.asRetriever();\n                    \t\n                    \tconst prompt =\n                    \t  PromptTemplate.fromTemplate(`Answer the question based only on the following context:\n                    \t{context}\n                    \t\n                    \tQuestion: {question}`);\n                    \t\n                    \tconst serializeDocs = (docs) => docs.map((doc) => doc.pageContent).join(\"\\n\");\n                    \t\n                    \tconst chain = RunnableSequence.from([\n                    \t  {\n                    \t\tcontext: retriever.pipe(serializeDocs),\n                    \t\tquestion: new RunnablePassthrough()\n                    \t  },\n                    \t  prompt,\n                    \t  model,\n                    \t  new StringOutputParser(),\n                    \t]);\n                    \t\n                    \tconst result = await chain.invoke(\"What do you mean by guided Discovery\");\n                    \t\n                    \tconsole.log(result);\n                    \t                \t \noutput:       \n\nGuided Discovery refers to an instructional approach or teaching method that encourages children to make connections and build concepts through interactive experiences with objects and people. In this approach, teachers facilitate the learning process by providing guidance and support, rather than simply providing information or answers. The focus is on allowing children to explore and discover knowledge and understanding on their own, fostering their critical thinking, problem-solving, and decision-making skills.Guided Discovery refers to an instructional approach or teaching method that encourages children to make connections and build concepts through interactive experiences with objects and people. In this approach, teachers facilitate the learning process by providing guidance and support, rather than simply providing information or answers. The focus is on allowing children to explore and discover knowledge and understanding on their own, fostering their critical thinking, problem-solving, and decision-making skills. </textarea></div><div class=\"fusion-text fusion-text-34\"><p>In this example,  the system incorporates information from the PDF book into its knowledge base, expanding its potential for answering questions accurately. The retrieved context helps the LLM generate responses that are relevant to the specific question and the information available in the book. Retrieval improves the chances of producing factual and well-grounded responses, reducing the risk of generating inaccurate or misleading information.</p>\n<p>This example demonstrates how RAG can effectively combine retrieval and generation to create more knowledgeable, contextually aware, and accurate responses, drawing on external knowledge sources to enhance the capabilities of LLMs.</p>\n</div><div class=\"fusion-title title fusion-title-30 fusion-sep-none fusion-title-text fusion-title-size-two\" style=\"--awb-text-color:#202020;--awb-font-size:35px;\" id=\"Memory1\"><h2 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:35;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><h2><span style=\"font-weight: 400;\">5. Memory</span></h2></a></h2></div><div class=\"fusion-title title fusion-title-31 fusion-sep-none fusion-title-text fusion-title-size-three\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:28px;\" id=\"Memory\"><h3 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:28;--minFontSize:28;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">5.1 Memory</span></a></h3></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-9 hover-type-none\"><img decoding=\"async\" width=\"1201\" height=\"566\" alt=\"Memory\" title=\"Memory\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Memory.webp\" class=\"lazyload img-responsive wp-image-15224\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271201%27%20height%3D%27566%27%20viewBox%3D%270%200%201201%20566%27%3E%3Crect%20width%3D%271201%27%20height%3D%27566%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-200x94.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-300x141.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-400x189.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-600x283.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-768x362.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-800x377.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory-1024x483.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Memory.webp 1201w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1201px\" /></span></div><div class=\"fusion-text fusion-text-35\"><p><span style=\"font-weight: 400;\">Memory in LangChain plays a crucial role in building intelligent and interactive workflows. It allows you to store and reuse information across different interactions, fostering context awareness and personalized experiences.</span></p>\n</div><div class=\"fusion-title title fusion-title-32 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Memory_in_a_Chatbot\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">5.1.1 Why use Memory in a Chatbot?</span></a></h4></div><div class=\"fusion-text fusion-text-36\"><p><b>Context awareness<br />\n</b><span style=\"font-weight: 400;\">Remember past interactions and user preferences to deliver relevant responses and experiences.</span></p>\n<p><b>Personalization<br />\n</b><span style=\"font-weight: 400;\">Adapt to individual users based on their stored information and preferences.</span></p>\n<p><b>Efficiency<br />\n</b><span style=\"font-weight: 400;\">Avoid repetitive processing by reusing cached data and stored outputs.</span></p>\n<p><b>Consistency<br />\n</b><span style=\"font-weight: 400;\">Maintain consistent responses and avoid contradictions across interactions.</span></p>\n</div><div class=\"fusion-title title fusion-title-33 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"memory_in_LangChain\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">5.1.2 Types of memory in LangChain</span></a></h4></div><div class=\"fusion-text fusion-text-37\"><p><b>Conversation Buffer<br />\n</b><span style=\"font-weight: 400;\">Stores recent chat messages, enabling context awareness and smoother conversation flow.</span></p>\n<p><b>Conversation Knowledge Graph<br />\n</b><span style=\"font-weight: 400;\">Captures extracted entities and relationships for personalized and knowledge-based interactions.</span></p>\n<p><b>Conversation Summary<br />\n</b><span style=\"font-weight: 400;\">Creates concise summaries of past conversations for easier reference and analysis.</span></p>\n<p><b>Custom Memory Classes<br />\n</b><span style=\"font-weight: 400;\">Allows you to define your own memory stores to manage specific data types relevant to your needs.</span></p>\n</div><div class=\"fusion-title title fusion-title-34 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">5.1.3 Benefits of using memory in Chatbot</span></a></h4></div><div class=\"fusion-text fusion-text-38\" id=\"memory_in_Chatbot\"><p><span style=\"font-weight: 400;\">Make your LangChain Chatbot more interactive and user-friendly by personalizing responses and remembering past interactions. By remembering the conversation flow, your chatbot can avoid awkward jumps or contradicting statements. Imagine discussing a movie then suddenly being asked about your favorite food! It allows for natural back-and-forth conversations, making the interaction feel more human-like and engaging.</span></p>\n</div><div class=\"fusion-title title fusion-title-35 fusion-sep-none fusion-title-text fusion-title-size-four\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:24px;\" id=\"Example_of_Memory\"><h4 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:24;--minFontSize:24;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><span style=\"font-weight: 400;\">5.1.4 Example of Memory</span></a></h4></div><style type=\"text/css\" scopped=\"scopped\">.fusion-syntax-highlighter-15 > .CodeMirror, .fusion-syntax-highlighter-15 > .CodeMirror .CodeMirror-gutters {background-color:var(--awb-color1);}.fusion-syntax-highlighter-15 > .CodeMirror .CodeMirror-gutters { background-color: var(--awb-color2); }.fusion-syntax-highlighter-15 > .CodeMirror .CodeMirror-linenumber { color: var(--awb-color8); }</style><div class=\"fusion-syntax-highlighter-container fusion-syntax-highlighter-15 fusion-syntax-highlighter-theme-light\" style=\"opacity:0;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;font-size:14px;border-width:1px;border-style:solid;border-color:var(--awb-color3);\"><div class=\"syntax-highlighter-copy-code\"><span class=\"syntax-highlighter-copy-code-title\" data-id=\"fusion_syntax_highlighter_15\" style=\"font-size:14px;\">Copy to Clipboard</span></div><label for=\"fusion_syntax_highlighter_15\" class=\"screen-reader-text\">Syntax Highlighter</label><textarea class=\"fusion-syntax-highlighter-textarea\" id=\"fusion_syntax_highlighter_15\" data-readOnly=\"nocursor\" data-lineNumbers=\"1\" data-lineWrapping=\"\" data-theme=\"default\" data-mode=\"text/x-sh\">import { BufferMemory } from \"langchain/memory\";\nimport {\n  ChatPromptTemplate,\n  MessagesPlaceholder,\n} from \"langchain/prompts\";\nimport { RunnableSequence } from \"langchain/schema/runnable\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai”;\n\nconst model = new ChatOpenAI({\nopenAIApiKey:”Your Api key”,\nTemperature: 0.5,\n});\nconst prompt = ChatPromptTemplate.fromMessages([\n  [\"system\", \"You are a helpful chatbot\"],\n  new MessagesPlaceholder(\"history\"),\n  [\"human\", \"{input}\"],\n]);\n\n// Default \"inputKey\", \"outputKey\", and \"memoryKey values would work here\n// but we specify them for clarity.\nconst memory = new BufferMemory({\n  returnMessages: true,\n  memoryKey: \"history\",\n  inputKey: \"input\",\n  outputKey: \"output\",\n  });\n\nconsole.log(await memory.loadMemoryVariables({}));\n\n/*\n  { history: [] }\n*/\n\nconst chain = RunnableSequence.from([\n  {\n    input: (initialInput) => initialInput.input,\n    memory: () => memory.loadMemoryVariables({}),\n  },\n  {\n    input: (previousOutput) => previousOutput.input,\n    history: (previousOutput) => previousOutput.memory.history,\n  },\n  prompt,\n  model,\n]);\n\nconst inputs = {\n  input: \"Hey, I am Rahul! and I love to chat and travel. My profession is lawyer”,\n};\n\nconst response = await chain.invoke(inputs);\n\nconsole.log(response);\n\nawait memory.saveContext(inputs,{\n output: response.content,\n});\n\nconst inputs2={\nInput:”What’s my name and what do I love?”\n};\nconst response2 = await chain.invoke(inputs2);\nconsole.log(response2);\n\nconst inputs3={\nInput:”What’s my name and what is my profession?”\n};\nconst response3 = await chain.invoke(inputs3);\nconsole.log(response3);\n\n\nOutput:\n\n{ history: [] }\nAIMessage {\n  lc_serializable: true,\n  lc_kwargs: {\n    content: \"Hi Rahul! Nice to meet you. I'm glad to hear that you enjoy chatting and traveling. Being a lawyer must be an interesting profession. How long have you been practicing law?\",\n    additional_kwargs: { function_call: undefined }\n  },\n  lc_namespace: [ 'langchain', 'schema' ],\n  content: \"Hi Rahul! Nice to meet you. I'm glad to hear that you enjoy chatting and traveling. Being a lawyer must be an interesting profession. How long have you been practicing law?\",\n  name: undefined,\n  additional_kwargs: { function_call: undefined }\n}\nAIMessage {\n  lc_serializable: true,\n  lc_kwargs: {\n    content: \"Your name is Rahul, and you mentioned that you love to chat and travel. Is there anything specific you'd like to chat about or any travel destinations you're interested in?\",\n    additional_kwargs: { function_call: undefined }\n  },\n  lc_namespace: [ 'langchain', 'schema' ],\n  content: \"Your name is Rahul, and you mentioned that you love to chat and travel. Is there anything specific you'd like to chat about or any travel destinations you're interested in?\",\n  name: undefined,\n  additional_kwargs: { function_call: undefined }\n}\nAIMessage {\n  lc_serializable: true,\n  lc_kwargs: {\n    content: 'Your name is Rahul and your profession is a lawyer.',\n    additional_kwargs: { function_call: undefined }\n  },\n  lc_namespace: [ 'langchain', 'schema' ],\n  content: 'Your name is Rahul and your profession is a lawyer.',\n  name: undefined,\n  additional_kwargs: { function_call: undefined }\n}\n</textarea></div><div class=\"fusion-text fusion-text-39\"><p>In this example, memory enables context-aware conversations. The chatbot can remember past information and use it to create more relevant and engaging responses. BufferMemory is a simple type of memory that stores a limited history of messages. Memory is integrated into the chatbot's processing using RunnableSequence, allowing it to access and update memory at different stages. Prompts play a crucial role in incorporating memory into the generation process. Saving responses to memory along with their corresponding inputs creates a rich context for future interactions.</p>\n</div><div class=\"fusion-title title fusion-title-36 fusion-sep-none fusion-title-text fusion-title-size-two\" style=\"--awb-text-color:#202020;--awb-margin-bottom:30px;--awb-font-size:35px;\" id=\"Conclusion\"><h2 class=\"fusion-title-heading title-heading-left fusion-responsive-typography-calculated\" style=\"font-family:&quot;Plus Jakarta Sans&quot;;font-style:normal;font-weight:300;margin:0;font-size:1em;letter-spacing:-0.015em;text-transform:var(--awb-typography1-text-transform);--fontSize:35;line-height:1.5;text-shadow:0px;\"><a href=\"#intro\" class=\"awb-custom-text-color awb-custom-text-hover-color\" target=\"_self\"><h2><span style=\"font-weight: 400;\">6. Conclusion</span></h2></a></h2></div><div class=\"fusion-image-element \" style=\"--awb-caption-title-font-family:var(--h2_typography-font-family);--awb-caption-title-font-weight:var(--h2_typography-font-weight);--awb-caption-title-font-style:var(--h2_typography-font-style);--awb-caption-title-size:var(--h2_typography-font-size);--awb-caption-title-transform:var(--h2_typography-text-transform);--awb-caption-title-line-height:var(--h2_typography-line-height);--awb-caption-title-letter-spacing:var(--h2_typography-letter-spacing);\"><span class=\" fusion-imageframe imageframe-none imageframe-10 hover-type-none\"><img decoding=\"async\" width=\"1201\" height=\"566\" alt=\"Memory - LangChain\" title=\"Conclusion\" src=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion.webp\" data-orig-src=\"https://www.deligence.com/wp-content/uploads/2024/02/Conclusion.webp\" class=\"lazyload img-responsive wp-image-15227\" srcset=\"data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%271201%27%20height%3D%27566%27%20viewBox%3D%270%200%201201%20566%27%3E%3Crect%20width%3D%271201%27%20height%3D%27566%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E\" data-srcset=\"https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-200x94.webp 200w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-300x141.webp 300w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-400x189.webp 400w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-600x283.webp 600w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-768x362.webp 768w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-800x377.webp 800w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion-1024x483.webp 1024w, https://determinate-arrant-florencio.ngrok-free.dev/backup151025/wp-content/uploads/2024/02/Conclusion.webp 1201w\" data-sizes=\"auto\" data-orig-sizes=\"(max-width: 1024px) 100vw, (max-width: 640px) 100vw, 1201px\" /></span></div><div class=\"fusion-text fusion-text-40\"><p><span style=\"font-weight: 400;\">In this blog post, we've explored the exciting potential of LangChain to build powerful and versatile chatbots. We've seen how LangChain simplifies conversation flows, enhances context awareness, and empowers developers to craft unique conversational experiences.</span></p>\n<p><span style=\"font-weight: 400;\">By leveraging retrieval-augmented generation (RAG) with Pinecone's efficient embedding retrieval, we can push the boundaries of chatbot intelligence, enabling them to access and integrate information seamlessly. This paves the way for more engaging, informative, and human-like interactions.</span></p>\n<p><span style=\"font-weight: 400;\">Remember, LangChain is more than just a technical solution; it's a gateway to crafting chatbots that are truly game-changing. With its flexibility and power, LangChain empowers developers to bring their chatbot visions to life, shaping the future of intelligent conversation.</span></p>\n<p><span style=\"font-weight: 400;\">So, are you ready to take your chatbot development to the next level? Start exploring LangChain and its potential to revolutionize your conversational AI!</span></p>\n<p><span style=\"font-weight: 400;\">Explore our AI Powered Chatbot Crafted Using LangChainJS, OpenAI, and Pinecone by our Team from Here: </span><strong><a href=\"http://hrchatbot.deligence.ca/chat\">LangChain Chatbot</a></strong></p>\n<p>You can check out our <strong><a href=\"/ai-services/langchain-services/\">LangChain Services</a></strong> as well.</p>\n</div></div></div><div class=\"fusion-layout-column fusion_builder_column fusion-builder-column-2 awb-sticky awb-sticky-small awb-sticky-medium awb-sticky-large fusion_builder_column_1_4 1_4 fusion-flex-column fusion-flex-align-self-flex-start Scroll fusion-no-small-visibility\" style=\"--awb-padding-left:20px;--awb-bg-size:cover;--awb-border-color:var(--awb-color4);--awb-border-left:2px;--awb-border-style:solid;--awb-width-large:25%;--awb-margin-top-large:100px;--awb-spacing-right-large:7.68%;--awb-margin-bottom-large:20px;--awb-spacing-left-large:7.68%;--awb-width-medium:100%;--awb-order-medium:0;--awb-spacing-right-medium:1.92%;--awb-spacing-left-medium:1.92%;--awb-width-small:100%;--awb-order-small:0;--awb-spacing-right-small:1.92%;--awb-spacing-left-small:1.92%;--awb-sticky-offset:120px;\" data-scroll-devices=\"small-visibility,medium-visibility,large-visibility\"><div class=\"fusion-column-wrapper fusion-column-has-shadow fusion-flex-justify-content-flex-start fusion-content-layout-column\"><div class=\"fusion-text fusion-text-41 Scroll\"><p><a href=\"#introduction\">1. Inroduction</a><br />\n<a href=\"#setting\">2. Setting Up the Development Environment</a><br />\n<a href=\"#nextjs\">    – 2.1 Next.js</a><br />\n<a href=\"#pinecone\">    – 2.2 Pinecone</a><br />\n<a href=\"#openAI\">    – 2.3 LangChain and OpenAI API Key</a><br />\n<a href=\"#building_blocks\">3. Understanding the Building Blocks</a><br />\n<a href=\"#prompt_templates\">    – 3.1 Prompt Templates</a><br />\n<a href=\"#Example_of_Prompt_Template\">        — 3.1.1 Example of Prompt Template in LangChain</a><br />\n<a href=\"#prompt_templates\">    – 3.2 Output Parser</a><br />\n<a href=\"#types_of_Output_Parsers \">        — 3.2.1 Different types of Output Parsers in LangChain</a><br />\n<a href=\"#Stop_Sequence\">    – 3.3 Stop Sequence</a><br />\n<a href=\"#Example_of_Stop_Sequence\">        — 3.3.1 Example of Stop Sequence</a><br />\n<a href=\"#Chatbot_Interactions\">4. How To Enhance Your Chatbot's Interactions</a><br />\n<a href=\"#Function_Schema\">    – 4.1 Use Function Schema</a><br />\n<a href=\"#Key_Components\">        — 4.1.1 Key Components of Function Schema</a><br />\n<a href=\"#Benefits_of_Function Schema\">        — 4.1.2 Benefits of using Function Schema</a><br />\n<a href=\"#Function_Schema_for_chatbot\">        — 4.1.3 Example of using Function Schemas for specific tasks in a chatbot</a><br />\n<a href=\"#Runnable_Sequence\">    – 4.2 Use Runnable Sequence</a><br />\n<a href=\"#example_of_Runnable_Sequence\">        — 4.2.1 Here's an example of Runnable Sequence in LangChain</a><br />\n<a href=\"#Runnable_Map\">    – 4.3 Use Runnable Map</a><br />\n<a href=\"#Runnable_Map_Work\">        — 4.3.1 How does Runnable Map Work</a><br />\n<a href=\"#Benefits_of_Runnable_Map\">        — 4.3.2 Benefits of Runnable Map</a><br />\n<a href=\"#Example_of_Runnable_Map\">        — 4.3.3 Example of Runnable Map</a><br />\n<a href=\"#Augmented_Generation\">    – 4.4 Use Retrieval Augmented Generation (RAG)</a><br />\n<a href=\"#RAG_work\">        — 4.4.1 How does RAG work</a><br />\n<a href=\"#Benefits_of_using_RAG\">        — 4.4.2 Benefits of using RAG in LangChain</a><br />\n<a href=\"#RAG_in_Chatbot\">        — 4.4.3 How can RAG be used in a Chatbot</a><br />\n<a href=\"#Cases_of_RAG\">        — 4.4.4 Use Cases of RAG in Chatbots</a><br />\n<a href=\"#Example_of_RAG\">        — 4.4.5 Example of RAG</a><br />\n<a href=\"#Memory\">5. Memory</a><br />\n<a href=\"#Memory1\">    – 5.1 Memory</a><br />\n<a href=\"#Memory_in_a_Chatbot\">        — 5.1.1 Why use Memory in a Chatbot?</a><br />\n<a href=\"#memory_in_LangChain\">        — 5.1.2 Types of memory in LangChain</a><br />\n<a href=\"#memory_in_Chatbot\">        — 5.1.3 Benefits of using memory in Chatbot</a><br />\n<a href=\"#Example_of_Memory\">        — 5.1.4 Example of Memory</a><br />\n<a href=\"#Conclusion\">6. Conclusion</a></p>\n</div></div></div></div></div>\n","date":"2024-02-29T16:17:31","author":{"node":{"name":"Sanjay Kumar","avatar":{"url":"https://secure.gravatar.com/avatar/12cd5109e81ca7f47c3bdfd017c1351234efe746c16d7811a74e031e6887c0e7?s=96&d=mm&r=g"}}},"featuredImage":{"node":{"altText":"","gatsbyImageData":null}}}},"pageContext":{"id":"cG9zdDoxNTE5OA=="}},"staticQueryHashes":[],"slicesMap":{"footer":"footer","header":"header"}}